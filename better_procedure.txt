
1)	For bi and ba algorithms separately, see if there is a correlation between extend and jointspace distance traveled.
/*    1.1)	Start with one QQ-plot and one histogram for each algorithm.
		OH my, it's definetely not normally distributed.
		  The QQ-plot is not a straight line, and we have positive skew.
     1.2)	Apply the log-transform to get normally distributed data.
     1.3)	Get one new QQ-plot and one new histogram for each algorithm.
		Sweet mother, it looks like a linear relationship, and no skew!
		Now, just to be extremely sure: Apply a normality test:
		  Shapiro Wilks Test: shapiro.test()
		  A p-value over 0.05 is what we want! (because p-value < 0.05 means it's not normally distributed)
		  There's a slight non-normality in our large sample set, so we get a too low p-value.
		  However, in the statistic's we're going to do, the non-normality is less of a problem when the sample size gets large.
		  And our sample size is large!
     1.4)	Now that we finally have approximately (acceptably) normally distributed data,
		we want to find out if there is correlation between extend and jointspace distance traveled.
*/		We can get an idea using a scatter plot (it's neither a vertical nor a horizontal line!).
		Now, the relationship we're testing is not linear, neither is the data 100 % normally distributed.
		So, instead of using Pearson's Correlation Coefficient,
		we use Spearman's Rank Correlation Coefficient:
		  NOTE: This test can be applied in the case of non-normality and for nonlinear relationships.
		  SO we use it on the NON-TRANSFORMED data.
		  cor.test(extend,jointspace_distance_not_transformed_at_all,method="spearman")
		  It gives a p-value. IF this p-value is very small (p-value < 0.05)
		  there is correlation. This is what we expect.
    1.5)	Based on the result obtained using the correlation test,
		we conclude that extend and jointspace distance traveled are correlated.
		This means we can choose an extend value for which we can expect a certain jointspace distance.
		We choose, for each algorithm, the extend value which produces the smallest median jointspace distance.
2)	We want to know if one algorithm is better than the other, so basically, if there is a difference.
	It would also be nice to have an idea which one is the better.
	So we want to see if the jointspace distances
    2.1)	Log-transform the big data sets (for the chosen extends).
		Make QQ-plot to verify that it is normally distributed.
		  AND IT DAMN WELL SHOULD BE!
		On the log-transformed (normally distributed) data,
		test for equality of variances.
		Do this using Fisher's F-test (which compares variances of two samples from normally distributed populations).
		  A small p-value means equal variances.
		  We will get a large p-value, so the variances are NOT equal.
    2.2)	Since the variances are different, the method we will use to test for difference in means,
		is: Welch's t-test: t.test(Y,X, var.equal = FALSE)
		The test null hypothesis is the two means are equal.
		The two-sided alternative hypothesis is that the two means are not equal.
		So, a small p-value is UNDESIRABLE, because it would mean that the means are equal.
		  Eg. we want a large p-value to ensure the means are different.
		We get large p-value and conclude that one algorithm must be better than the other.
		The one with the smallest mean is the better algorithm.